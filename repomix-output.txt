This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-29T07:55:39.059Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.env.example
.gitignore
app.py
config.py
main.py
raft_database.py
raft_node.py
raft_pb2_grpc.py
raft_pb2.py
raft.proto
README.md
requirements.txt
templates/index.html
test_mongodb.py
test_node_status.py
test_raft_nodes.py

================================================================
Repository Files
================================================================

================
File: .env.example
================
PEERS=localhost:5000,localhost:5001,localhost:5002,localhost:5003,localhost:5004
MONGODB_URI=mongodb://localhost:27017
DB_NAME=raft
COLLECTION_NAME=logs

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

================
File: app.py
================
from flask import Flask, render_template
import grpc
import raft_pb2
import raft_pb2_grpc
import pymongo
from datetime import datetime

app = Flask(__name__)

# Configuration
NODES = [
    {'id': 0, 'port': 5000},
    {'id': 1, 'port': 5001},
    {'id': 2, 'port': 5002},
    {'id': 3, 'port': 5003},
    {'id': 4, 'port': 5004}
]
MONGODB_URI = "mongodb://localhost:27017"
DB_NAME = "raft"
COLLECTION_NAME = "logs"

def get_node_status(port):
    try:
        channel = grpc.insecure_channel(f'localhost:{port}')
        stub = raft_pb2_grpc.RaftServiceStub(channel)
        response = stub.Status(raft_pb2.StatusRequest())
        return {
            'status': 'online',
            'state': response.state,
            'term': response.current_term,
            'logs': response.log_count,
            'is_leader': response.is_leader
        }
    except:
        return {'status': 'offline', 'state': 'unknown', 'term': -1, 'logs': 0}

@app.route('/')
def index():
    nodes_status = []
    for node in NODES:
        status = get_node_status(node['port'])
        status['port'] = node['port']
        status['id'] = node['id']
        nodes_status.append(status)
    
    # Get logs from MongoDB
    client = pymongo.MongoClient(MONGODB_URI)
    db = client[DB_NAME]
    logs = list(db[COLLECTION_NAME].find().sort('timestamp', -1).limit(10))
    client.close()
    
    return render_template('index.html', nodes=nodes_status, logs=logs)

if __name__ == '__main__':
    app.run(port=8080, debug=True)

================
File: config.py
================
import argparse

def get_config():
    parser = argparse.ArgumentParser(description='Raft Configuration')

    # Define the parameters required for the Raft nodes
    parser.add_argument('--node_id', type=int, required=True, help='ID of the node (0, 1, 2, ...)')
    parser.add_argument('--port', type=int, default=5000, help='Port for the node to listen on (default: 5000)')
    parser.add_argument('--peers', nargs='+', required=True, help='List of peer addresses (e.g., localhost:5001 localhost:5002)')

    # Database configuration
    parser.add_argument('--db_uri', type=str, required=True, help='MongoDB URI for the database')
    parser.add_argument('--db_name', type=str, default='raft_db', help='Database name (default: raft_db)')
    parser.add_argument('--db_collection', type=str, default='logs', help='Collection name for logs (default: logs)')

    args = parser.parse_args()

    return {
        'node_id': args.node_id,
        'port': args.port,
        'peers': args.peers,
        'db_uri': args.db_uri,
        'db_name': args.db_name,
        'db_collection': args.db_collection,
    }

if __name__ == "__main__":
    config = get_config()
    print("Configuration:")
    for key, value in config.items():
        print(f"{key}: {value}")

================
File: main.py
================
import multiprocessing
import config
from dotenv import load_dotenv
import os
import argparse
from raft_node import Node  # Assuming Node class is defined in raft_node.py

def run_node(node_id, port, peers, db_uri, db_name, db_collection):
    # Create a Node instance and run the server
    node = Node(node_id=node_id, db_uri=db_uri, db_name=db_name, db_collection=db_collection)

    # Initialize peers (including localhost addresses)
    node.peers = [f'localhost:{p}' for p in range(5000, 5000 + len(peers))]

    # Start the gRPC server for the node
    node.run(port)  # This starts the gRPC server

    # Start heartbeat for the leader node
    if node.state == "leader":
        node.start_heartbeat()  # This could be managed separately if needed.

if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()

    parser = argparse.ArgumentParser(description="Run a Raft node.")
    parser.add_argument('--node_id', type=int, required=True, help="The ID of the node.")
    parser.add_argument('--port', type=int, default=5000, help="The port on which the node will run.")
    parser.add_argument('--peers', nargs='+', required=True, help="List of peer addresses.")
    parser.add_argument('--db_uri', default=os.getenv('MONGODB_URI'), help="The URI of the MongoDB database.")
    parser.add_argument('--db_name', default=os.getenv('DB_NAME', 'raft'), help="The name of the MongoDB database.")
    parser.add_argument('--db_collection', default=os.getenv('COLLECTION_NAME', 'logs'), help="The name of the MongoDB collection.")

    args = parser.parse_args()

    # Create a process for each node
    processes = []
    for id in range(len(args.peers)):
        port = args.port + id
        proc = multiprocessing.Process(target=run_node, args=(id, port, args.peers, args.db_uri, args.db_name, args.db_collection))
        processes.append(proc)
        proc.start()  # Start the node process

    # Optionally: wait for all processes to finish
    for proc in processes:
        proc.join()  # Block until each node process is finished

    print("All nodes have been started.")

================
File: raft_database.py
================
import pymongo
import time
import threading
import logging
import uuid
import raft_pb2

# Configure logging (important!)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class Database:
    def __init__(self, uri, db_name, collection_name):
        self.client = pymongo.MongoClient(uri)
        self.db = self.client[db_name]
        self.collection = self.db[collection_name]
        self.lock = threading.Lock()  # Add a lock for thread safety

        # Create index if it doesn't exist (crucial for performance)
        try:
            self.collection.create_index([("index", pymongo.ASCENDING)])
        except pymongo.errors.PyMongoError as e:
            logging.error(f"Error creating index: {e}")

    def append_entry(self, entry):
        """Append a log entry to the database."""
        with self.lock:  # Acquire the lock before any database operation
            max_retries = 5
            retry_delay = 1
            for attempt in range(max_retries):
                try:
                    # Ensure a unique ID is generated for the entry
                    entry['_id'] = str(uuid.uuid4())
                    result = self.collection.insert_one(entry)  # Use insert_one to add the document
                    logging.info(f"Successfully inserted log entry: {entry}")
                    break
                except pymongo.errors.PyMongoError as e:
                    if attempt == max_retries - 1:
                        logging.error(f"Database insert failed after multiple retries: {e}")
                        raise  # Re-raise the exception if all retries fail
                    else:
                        logging.warning(f"Database insert failed (attempt {attempt + 1}/{max_retries}): {e}. Retrying in {retry_delay} seconds...")
                        time.sleep(retry_delay)
                        retry_delay *= 2

    def get_entry(self, index):
        """Retrieve a log entry based on its index."""
        with self.lock:
            try:
                entry = self.collection.find_one({"index": index})
                if entry:
                    # Decode the command to return a structured LogEntry object
                    log_entry = raft_pb2.LogEntry(
                        term=entry['term'],
                        command=entry['command'].encode(),  # Convert command to bytes
                        timestamp=entry['timestamp']
                    )
                    logging.info(f"Retrieved log entry: {log_entry}")
                    return log_entry
                logging.warning(f"No entry found for index: {index}")
                return None
            except Exception as e:
                logging.error(f"Error retrieving entry: {e}")
                return None

    def close(self):
        """Close the database connection."""
        self.client.close()
        logging.info("Database connection closed.")

================
File: raft_node.py
================
import time
import random
import uuid
import grpc
import logging
from concurrent import futures
import pymongo
import raft_pb2, raft_pb2_grpc
import raft_database
import threading



class Node(raft_pb2_grpc.RaftServiceServicer):
    def __init__(self, node_id, db_uri, db_name, db_collection):
        self.node_id = node_id
        self.state = "follower"
        self.current_term = 0
        self.voted_for = None
        self.log = []  # In-memory log
        self.commit_index = 0
        self.last_applied = 0
        self.election_timer = None
        self.last_applied_index = 0
        node_db_name = f"{db_name}_node_{node_id}"
        self.db = raft_database.Database(db_uri, node_db_name, db_collection)
        self.peers = {}
        self.lock = threading.Lock()
        self.heartbeat_interval = 1  # Heartbeat interval in seconds
        self.running = True
        self.port = None  # Port for the gRPC server
        

        self.recover_data()
        threading.Thread(target=self.heartbeat, daemon=True).start()  # Start heartbeat thread


    
    
    def recover_data(self):
        # Load the log entries from the database sorted by index
        log_entries = []
        for entry in self.db.collection.find().sort("index", pymongo.ASCENDING):
            entry_obj = raft_pb2.LogEntry(
                term=entry['term'], 
                command=entry['command'].encode(),  # Ensure command is in bytes
                timestamp=entry['timestamp']
            )
            log_entries.append(entry_obj)
        self.log = log_entries
        self.last_applied_index = len(self.log)  # Set according to loaded logs

    def append_entry(self, entry):
        entry['index'] = len(self.log) + 1  # Assign the index
        entry['_id'] = str(uuid.uuid4())   # Unique ID for the entry
        self.db.append_entry(entry)          # Save to the database
        self.log.append(raft_pb2.LogEntry(term=entry['term'], command=entry['command'].encode(), timestamp=entry['timestamp']))

    def RequestVote(self, request, context):
        response = raft_pb2.RequestVoteResponse()
        if request.term > self.current_term:
            self.current_term = request.term
            self.voted_for = None
            self.state = "follower"  # Reset state on term increase
        # Voting logic
        if self.voted_for is None or self.voted_for == request.candidateId:
            response.term = self.current_term
            response.voteGranted = True
            self.voted_for = request.candidateId
        else:
            response.term = self.current_term
            response.voteGranted = False
        return response

    def AppendEntries(self, request, context):
        response = raft_pb2.AppendEntriesResponse()
        with self.lock:
            if request.term > self.current_term:
                self.current_term = request.term
                self.state = "follower"
                self.voted_for = None  # Reset voted_for to allow future elections

            # Verify the log's previous index and term
            if request.prevLogIndex < len(self.log) and self.log[request.prevLogIndex].term == request.prevLogTerm:
                # Valid log entry, append new entries
                for entry in request.entries:
                    self.append_entry({
                        "term": entry.term,
                        "command": entry.command.decode(),  # Convert back from bytes
                        "timestamp": entry.timestamp
                    })
                response.success = True
                response.matchIndex = len(self.log)  # The index of the last entry
            else:
                response.success = False

            response.term = self.current_term  # Respond with current term
            return response
    def Heartbeat(self, request, context):
        response = raft_pb2.HeartbeatResponse()
        response.term = self.current_term
        response.success = True
        return response
    def heartbeat(self):
        while self.running:
            if self.state == "leader":
                for peer in self.peers:
                    with grpc.insecure_channel(peer) as channel:
                        stub = raft_pb2_grpc.RaftServiceStub(channel)
                        try:
                            stub.Heartbeat(raft_pb2.HeartbeatRequest(term=self.current_term, leaderId=self.node_id))
                        except grpc.RpcError as e:
                            logging.error(f"Error sending heartbeat to {peer}: {e}")
            time.sleep(self.heartbeat_interval)
            
    
    def run(self, port):
        """Start the gRPC server for the Raft node."""
        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
        raft_pb2_grpc.add_RaftServiceServicer_to_server(self, server)
        server.add_insecure_port(f'[::]:{port}')
        server.start()
        logging.info(f"Node {self.node_id} is listening on port {port}")
        server.wait_for_termination()  # Keep the server running
        
    def create_client(self, peer_address):
        """Create a gRPC client connection to a peer node."""
        channel = grpc.insecure_channel(peer_address)
        return raft_pb2_grpc.RaftServiceStub(channel)

    def query_peer_status(self, peer_address):
        """Query the status of a peer node."""
        client = self.create_client(peer_address)
        response = client.Status(raft_pb2.StatusRequest())
        return response
            
    def Status(self, request, context):
        return raft_pb2.StatusResponse(
            state=self.state,
            current_term=self.current_term,
            log_count=len(self.log),
            is_leader=(self.state == "leader")
        )
    
    def start_heartbeat(self):
        """Start the heartbeats for leader nodes."""
        while True:
            time.sleep(2)  # Heartbeat interval
            if self.state == "leader":
                for peer in self.peers:
                    self.send_heartbeat(peer)  # Call to send heartbeat to peers

    def send_heartbeat(self, peer):
        client = self.create_client(peer)
        try:
            response = client.Heartbeat(raft_pb2.HeartbeatRequest(term=self.current_term, leaderId=self.node_id))
            logging.info(f"Heartbeat sent from {self.node_id} to {peer}. Response: {response.success}")
        except grpc.RpcError as e:
            logging.error(f"Failed to send heartbeat to {peer}: {e}")
                    
        

    def close(self):
        self.db.close()
        self.running = False  # Use the existing gRPC server reference if needed
        
        
import config

if __name__ == "__main__":
    cfg = config.get_config()
    node_id = cfg['node_id']
    port = cfg['port']
    peers = cfg['peers']
    db_uri = cfg['db_uri']
    db_name = cfg['db_name']
    db_collection = cfg['db_collection']

    # Initialize your Raft Node
    node = Node(node_id=node_id, db_uri=db_uri, db_name=db_name, db_collection=db_collection)

    # Start the gRPC server, etc...

================
File: raft_pb2_grpc.py
================
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

import raft_pb2 as raft__pb2

GRPC_GENERATED_VERSION = '1.68.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    raise RuntimeError(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + f' but the generated code in raft_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    )


class RaftServiceStub(object):
    """Define the Raft service with all RPC methods
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.Status = channel.unary_unary(
                '/raft.RaftService/Status',
                request_serializer=raft__pb2.StatusRequest.SerializeToString,
                response_deserializer=raft__pb2.StatusResponse.FromString,
                _registered_method=True)
        self.RequestVote = channel.unary_unary(
                '/raft.RaftService/RequestVote',
                request_serializer=raft__pb2.RequestVoteRequest.SerializeToString,
                response_deserializer=raft__pb2.RequestVoteResponse.FromString,
                _registered_method=True)
        self.AppendEntries = channel.unary_unary(
                '/raft.RaftService/AppendEntries',
                request_serializer=raft__pb2.AppendEntriesRequest.SerializeToString,
                response_deserializer=raft__pb2.AppendEntriesResponse.FromString,
                _registered_method=True)
        self.Heartbeat = channel.unary_unary(
                '/raft.RaftService/Heartbeat',
                request_serializer=raft__pb2.HeartbeatRequest.SerializeToString,
                response_deserializer=raft__pb2.HeartbeatResponse.FromString,
                _registered_method=True)


class RaftServiceServicer(object):
    """Define the Raft service with all RPC methods
    """

    def Status(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def RequestVote(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def AppendEntries(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Heartbeat(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_RaftServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'Status': grpc.unary_unary_rpc_method_handler(
                    servicer.Status,
                    request_deserializer=raft__pb2.StatusRequest.FromString,
                    response_serializer=raft__pb2.StatusResponse.SerializeToString,
            ),
            'RequestVote': grpc.unary_unary_rpc_method_handler(
                    servicer.RequestVote,
                    request_deserializer=raft__pb2.RequestVoteRequest.FromString,
                    response_serializer=raft__pb2.RequestVoteResponse.SerializeToString,
            ),
            'AppendEntries': grpc.unary_unary_rpc_method_handler(
                    servicer.AppendEntries,
                    request_deserializer=raft__pb2.AppendEntriesRequest.FromString,
                    response_serializer=raft__pb2.AppendEntriesResponse.SerializeToString,
            ),
            'Heartbeat': grpc.unary_unary_rpc_method_handler(
                    servicer.Heartbeat,
                    request_deserializer=raft__pb2.HeartbeatRequest.FromString,
                    response_serializer=raft__pb2.HeartbeatResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'raft.RaftService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('raft.RaftService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class RaftService(object):
    """Define the Raft service with all RPC methods
    """

    @staticmethod
    def Status(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/raft.RaftService/Status',
            raft__pb2.StatusRequest.SerializeToString,
            raft__pb2.StatusResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def RequestVote(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/raft.RaftService/RequestVote',
            raft__pb2.RequestVoteRequest.SerializeToString,
            raft__pb2.RequestVoteResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def AppendEntries(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/raft.RaftService/AppendEntries',
            raft__pb2.AppendEntriesRequest.SerializeToString,
            raft__pb2.AppendEntriesResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def Heartbeat(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/raft.RaftService/Heartbeat',
            raft__pb2.HeartbeatRequest.SerializeToString,
            raft__pb2.HeartbeatResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

================
File: raft_pb2.py
================
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: raft.proto
# Protobuf Python Version: 5.28.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    28,
    1,
    '',
    'raft.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\nraft.proto\x12\x04raft\"<\n\x08LogEntry\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x0f\n\x07\x63ommand\x18\x02 \x01(\x0c\x12\x11\n\ttimestamp\x18\x03 \x01(\x03\"b\n\x12RequestVoteRequest\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x13\n\x0b\x63\x61ndidateId\x18\x02 \x01(\x05\x12\x14\n\x0clastLogIndex\x18\x03 \x01(\x03\x12\x13\n\x0blastLogTerm\x18\x04 \x01(\x03\"8\n\x13RequestVoteResponse\x12\x13\n\x0bvoteGranted\x18\x01 \x01(\x08\x12\x0c\n\x04term\x18\x02 \x01(\x05\"\x98\x01\n\x14\x41ppendEntriesRequest\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x10\n\x08leaderId\x18\x02 \x01(\x05\x12\x14\n\x0cprevLogIndex\x18\x03 \x01(\x03\x12\x13\n\x0bprevLogTerm\x18\x04 \x01(\x03\x12\x1f\n\x07\x65ntries\x18\x05 \x03(\x0b\x32\x0e.raft.LogEntry\x12\x14\n\x0cleaderCommit\x18\x06 \x01(\x03\"J\n\x15\x41ppendEntriesResponse\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x0f\n\x07success\x18\x02 \x01(\x08\x12\x12\n\nmatchIndex\x18\x03 \x01(\x03\"2\n\x10HeartbeatRequest\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x10\n\x08leaderId\x18\x02 \x01(\x05\"2\n\x11HeartbeatResponse\x12\x0c\n\x04term\x18\x01 \x01(\x05\x12\x0f\n\x07success\x18\x02 \x01(\x08\" \n\rStatusRequest\x12\x0f\n\x07node_id\x18\x01 \x01(\x05\"[\n\x0eStatusResponse\x12\r\n\x05state\x18\x01 \x01(\t\x12\x14\n\x0c\x63urrent_term\x18\x02 \x01(\x05\x12\x11\n\tlog_count\x18\x03 \x01(\x05\x12\x11\n\tis_leader\x18\x04 \x01(\x08\x32\x8e\x02\n\x0bRaftService\x12\x33\n\x06Status\x12\x13.raft.StatusRequest\x1a\x14.raft.StatusResponse\x12\x42\n\x0bRequestVote\x12\x18.raft.RequestVoteRequest\x1a\x19.raft.RequestVoteResponse\x12H\n\rAppendEntries\x12\x1a.raft.AppendEntriesRequest\x1a\x1b.raft.AppendEntriesResponse\x12<\n\tHeartbeat\x12\x16.raft.HeartbeatRequest\x1a\x17.raft.HeartbeatResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'raft_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_LOGENTRY']._serialized_start=20
  _globals['_LOGENTRY']._serialized_end=80
  _globals['_REQUESTVOTEREQUEST']._serialized_start=82
  _globals['_REQUESTVOTEREQUEST']._serialized_end=180
  _globals['_REQUESTVOTERESPONSE']._serialized_start=182
  _globals['_REQUESTVOTERESPONSE']._serialized_end=238
  _globals['_APPENDENTRIESREQUEST']._serialized_start=241
  _globals['_APPENDENTRIESREQUEST']._serialized_end=393
  _globals['_APPENDENTRIESRESPONSE']._serialized_start=395
  _globals['_APPENDENTRIESRESPONSE']._serialized_end=469
  _globals['_HEARTBEATREQUEST']._serialized_start=471
  _globals['_HEARTBEATREQUEST']._serialized_end=521
  _globals['_HEARTBEATRESPONSE']._serialized_start=523
  _globals['_HEARTBEATRESPONSE']._serialized_end=573
  _globals['_STATUSREQUEST']._serialized_start=575
  _globals['_STATUSREQUEST']._serialized_end=607
  _globals['_STATUSRESPONSE']._serialized_start=609
  _globals['_STATUSRESPONSE']._serialized_end=700
  _globals['_RAFTSERVICE']._serialized_start=703
  _globals['_RAFTSERVICE']._serialized_end=973
# @@protoc_insertion_point(module_scope)

================
File: raft.proto
================
syntax = "proto3";

package raft;

// Represents a single log entry
message LogEntry {
    int32 term = 1;             
    bytes command = 2;          
    int64 timestamp = 3;        
}

// Request for a vote during the leader election process
message RequestVoteRequest {
    int32 term = 1;             
    int32 candidateId = 2;      
    int64 lastLogIndex = 3;     
    int64 lastLogTerm = 4;      
}

// The response to a RequestVote
message RequestVoteResponse {
    bool voteGranted = 1;       
    int32 term = 2;             
}

// Request for appending log entries from the leader to followers
message AppendEntriesRequest {
    int32 term = 1;             
    int32 leaderId = 2;         
    int64 prevLogIndex = 3;     
    int64 prevLogTerm = 4;      
    repeated LogEntry entries = 5; 
    int64 leaderCommit = 6;     
}

// The response to an AppendEntries request
message AppendEntriesResponse {
    int32 term = 1;             
    bool success = 2;           
    int64 matchIndex = 3;       
}

// Heartbeat message from the leader to followers
message HeartbeatRequest {
    int32 term = 1;             
    int32 leaderId = 2;         
}

// Response to heartbeat request
message HeartbeatResponse {
    int32 term = 1;             
    bool success = 2;           
}

// Status request/response
message StatusRequest {
    int32 node_id = 1;
}
message StatusResponse {
    string state = 1;
    int32 current_term = 2;
    int32 log_count = 3; 
    bool is_leader = 4;

}

// Define the Raft service with all RPC methods
service RaftService {
    rpc Status(StatusRequest) returns (StatusResponse);
    rpc RequestVote(RequestVoteRequest) returns (RequestVoteResponse);
    rpc AppendEntries(AppendEntriesRequest) returns (AppendEntriesResponse);
    rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
}

================
File: README.md
================
# RAFT-CONSENSUS

## INSTRUCTIONS
1. Clone the repository
2. Run the following command to install the dependencies
```bash
py -m venv .venv
source .venv/bin/activate  # For Linux/macOS
.venv\Scripts\activate  # For Windows
pip install -r requirements.txt
```
3. Install mongodb and run the following command to start the server
[MongoDB Installation](https://www.mongodb.com/try/download/community-edition/releases?msockid=3b0ac080b3126d3c0845d5b4b2746c1a)


choose the appropriate version for your operating system, setup the server 

4. Run the following command to run the program
```bash
cd RAFT-CONSENSUS
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. raft.proto # Generate the gRPC files
```

5. Run the following command to start the server
```bash
python main.py --node_id 0 --port 5000 --peers localhost:5001 localhost:5002 localhost:5003 localhost:5004 localhost:5005 --db_uri mongodb://localhost:27017
```

6. Run the following command to start the web app status
```bash
py app.py 
```

================
File: requirements.txt
================
flask
requests
protobuf
grpcio
grpcio-tools
pymongo
python-dotenv
flask
asgiref

================
File: templates/index.html
================
<!DOCTYPE html>
<html>
<head>
    <title>Raft Nodes Status</title>
    <style>
        .node { margin: 10px; padding: 10px; border: 1px solid #ccc; }
        .online { background-color: #90EE90; }
        .offline { background-color: #FFB6C1; }
        .logs { margin-top: 20px; }
    </style>
</head>
<body>
    <h1>Raft Nodes Status</h1>
    
    <div class="nodes">
        {% for node in nodes %}
        <div class="node {{ node.status }}">
            <h3>Node {{ node.id }} (Port {{ node.port }})</h3>
            <p>Status: {{ node.status }}</p>
            <p>State: {{ node.state }}</p>
            <p>Term: {{ node.term }}</p>
            <p>Logs Count: {{ node.logs }}</p>
        </div>
        {% endfor %}
    </div>

    <div class="logs">
        <h2>Recent Logs</h2>
        <table border="1">
            <tr>
                <th>Term</th>
                <th>Command</th>
                <th>Timestamp</th>
            </tr>
            {% for log in logs %}
            <tr>
                <td>{{ log.term }}</td>
                <td>{{ log.command }}</td>
                <td>{{ log.timestamp }}</td>
            </tr>
            {% endfor %}
        </table>
    </div>
</body>
</html>

================
File: test_mongodb.py
================
import pymongo

def test_connection():
    client = pymongo.MongoClient("mongodb://localhost:27017/")
    db = client.raft
    print("MongoDB connection successful")
    print(f"Database names: {client.list_database_names()}")

if __name__ == "__main__":
    test_connection()

================
File: test_node_status.py
================
# test_node_status.py
import grpc
import raft_pb2
import raft_pb2_grpc
import unittest

class TestNodeStatus(unittest.TestCase):
    def setUp(self):
        self.channel = grpc.insecure_channel('localhost:5000')
        self.stub = raft_pb2_grpc.RaftServiceStub(self.channel)

    def test_node_status(self):
        request = raft_pb2.StatusRequest(node_id=0)
        try:
            response = self.stub.Status(request)
            print(f"Node state: {response.state}")
            print(f"Current term: {response.current_term}")
            print(f"Log count: {response.log_count}")
            print(f"Is leader: {response.is_leader}")
        except grpc.RpcError as e:
            print(f"Error connecting to node: {e}")

if __name__ == '__main__':
    unittest.main()

================
File: test_raft_nodes.py
================
import unittest
import time
import grpc
import pymongo
from dotenv import load_dotenv
import os
import raft_pb2
import raft_pb2_grpc
from raft_node import Node
import threading
import logging

class TestRaftNode(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        # Node configuration
        cls.base_port = 5000
        cls.num_nodes = 5
        cls.peers = [f'localhost:{cls.base_port + i}' for i in range(cls.num_nodes)]
        
        # Load environment variables
        load_dotenv()
        
        # MongoDB configuration
        cls.db_uri = "mongodb://localhost:27017"
        cls.db_name = "raft_test"
        cls.db_collection = "test_logs"
        
        # Clear test database
        client = pymongo.MongoClient(cls.db_uri)
        for i in range(cls.num_nodes):
            node_db_name = f"{cls.db_name}_node_{i}"
            client.drop_database(node_db_name)
        client.close()
        

    def setUp(self):
        self.nodes = []
        self.node_threads = []
        
        # Create and start nodes
        for i in range(self.num_nodes):
            node = Node(
                node_id=i,
                db_uri=self.db_uri,
                db_name=f"{self.db_name}_node_{i}",
                db_collection=self.db_collection
            )
            node.peers = self.peers
            self.nodes.append(node)
            
            # Start node in separate thread
            thread = threading.Thread(
                target=node.run,
                args=(self.base_port + i,)
            )
            thread.daemon = True
            thread.start()
            self.node_threads.append(thread)
        
        # Wait for nodes to start
        time.sleep(2)

    def tearDown(self):
        for node in self.nodes:
            node.close()
        time.sleep(1)
        
        if hasattr(self, 'client'):
            self.client.close()

    def test_node_initialization(self):
        """Test if nodes are properly initialized"""
        for i, node in enumerate(self.nodes):
            self.assertEqual(node.node_id, i)
            self.assertEqual(node.state, "follower")
            self.assertEqual(node.current_term, 0)
            self.assertIsNone(node.voted_for)

    def test_leader_election(self):
    """Test leader election process"""
    # Allow time for leader election
    time.sleep(5)
    
    # Count leaders
    leaders = [node for node in self.nodes if node.state == "leader"]
    
    # Verify exactly one leader
    self.assertEqual(len(leaders), 1, "Should be exactly one leader")
    
    # Verify other nodes are followers
    followers = [node for node in self.nodes if node.state == "follower"]
    self.assertEqual(len(followers), self.num_nodes - 1, 
                    "All other nodes should be followers")
    
    # Verify leader has highest term
    leader = leaders[0]
    for node in self.nodes:
        self.assertLessEqual(node.current_term, leader.current_term,
                           "Leader should have highest term")
    
    
    def test_leader_election_scenario(self):
        """Test the complete leader election process"""
        # Initial state check - all should be followers
        for node in self.nodes:
            self.assertEqual(node.state, "follower")
        
        # Select node 0 to become candidate
        candidate_node = self.nodes[0]
        candidate_node.state = "candidate"
        
        # Increment term and request votes
        candidate_node.current_term += 1
        for peer in candidate_node.peers:
            try:
                channel = grpc.insecure_channel(peer)
                stub = raft_pb2_grpc.RaftServiceStub(channel)
                
                # Create vote request
                request = raft_pb2.RequestVoteRequest(
                    term=candidate_node.current_term,
                    candidateId=candidate_node.node_id,
                    lastLogIndex=len(candidate_node.log),
                    lastLogTerm=candidate_node.current_term
                )
                
                # Send vote request
                response = stub.RequestVote(request)
                logging.info(f"Vote response from {peer}: {response.voteGranted}")
                
            except grpc.RpcError as e:
                logging.error(f"Failed to request vote from {peer}: {e}")
        
        # Wait for voting to complete
        time.sleep(2)
        
        # Verify election results
        vote_count = 1  # Candidate votes for itself
        for node in self.nodes[1:]:
            if node.voted_for == candidate_node.node_id:
                vote_count += 1
        
        # Check if candidate became leader (needs majority)
        if vote_count > len(self.nodes) // 2:
            self.assertEqual(candidate_node.state, "leader")
            logging.info(f"Node {candidate_node.node_id} became leader with {vote_count} votes")
        else:
            self.assertNotEqual(candidate_node.state, "leader")
            logging.info(f"Node {candidate_node.node_id} failed to become leader. Got {vote_count} votes")

    # def test_log_replication(self):
    #     """Test log replication and database storage"""
    #     # Wait for leader election
    #     time.sleep(5)
        
    #     # Find leader
    #     leader = None
    #     for node in self.nodes:
    #         if node.state == "leader":
    #             leader = node
    #             break
        
    #     self.assertIsNotNone(leader, "No leader found")
        
    #     # Create test entry
    #     test_entry = {
    #         "term": leader.current_term,
    #         "command": "test_command",
    #         "timestamp": int(time.time()),
    #         "index": len(leader.log)
    #     }
        
    #     # Append entry and write to database
    #     leader.append_entry(test_entry)
        
    #     # Wait for replication
    #     time.sleep(2)
        
    #     # Verify in MongoDB
    #     client = pymongo.MongoClient(self.db_uri)
    #     db = client[self.db_name]
    #     collection = db[self.db_collection]
        
    #     # Check database entries
    #     db_entries = list(collection.find({"command": "test_command"}))
    #     self.assertEqual(len(db_entries), 1, "Log entry not found in database")
        
    #     # Check if all nodes have the entry
    #     for node in self.nodes:
    #         self.assertEqual(len(node.log), 1, f"Node {node.node_id} did not replicate the log")
            
    #     client.close()

    # def test_status_query(self):
    #     """Test status query functionality and database storage"""
    #     # Create status collection
    #     client = pymongo.MongoClient(self.db_uri)
    #     db = client[self.db_name]
    #     status_collection = db['node_status']
    #     status_collection.delete_many({})  # Clear previous status
        
    #     for i, node in enumerate(self.nodes):
    #         # Get node status
    #         status = node.Status(raft_pb2.StatusRequest(), None)
    #         self.assertIsNotNone(status)
    #         self.assertEqual(status.log_count, len(node.log))
            
    #         # Store status in MongoDB
    #         status_doc = {
    #             "node_id": node.node_id,
    #             "state": status.state,
    #             "current_term": status.current_term,
    #             "log_count": status.log_count,
    #             "timestamp": int(time.time())
    #         }
    #         status_collection.insert_one(status_doc)
        
    #     # Verify status storage
    #     stored_status = list(status_collection.find())
    #     self.assertEqual(len(stored_status), len(self.nodes), 
    #                     "Not all node statuses were stored in database")
        
    #     client.close()

if __name__ == '__main__':
    unittest.main()
